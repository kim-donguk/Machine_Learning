{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day724_Gan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"14zcARmUDATW","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.examples.tutorials.mnist import input_data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j1L6g5TleHoK","colab_type":"code","outputId":"a43d063b-9bae-4b64-d795-fe9d374509f0","executionInfo":{"status":"ok","timestamp":1563950204355,"user_tz":-540,"elapsed":5692,"user":{"displayName":"김동욱","photoUrl":"https://lh5.googleusercontent.com/-rX2IX9qdYbU/AAAAAAAAAAI/AAAAAAAAAGE/Iyrqv3QIaEg/s64/photo.jpg","userId":"00810367570516642116"}},"colab":{"base_uri":"https://localhost:8080/","height":565}},"source":["mnist = input_data.read_data_sets(\"./mnist/data\", one_hot= True)\n","\n","#옵션 설정\n","total_epoch = 100\n","batch_size =100\n","learning_rate = 0.02\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0724 06:36:41.360783 140081129940864 deprecation.py:323] From <ipython-input-3-15e6802bad66>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","W0724 06:36:41.364447 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","W0724 06:36:41.367087 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","W0724 06:36:41.540096 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","Extracting ./mnist/data/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"stream","text":["W0724 06:36:41.811398 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","W0724 06:36:41.813281 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","W0724 06:36:41.974078 140081129940864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stderr"},{"output_type":"stream","text":["Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dokT2DTUesN4","colab_type":"code","colab":{}},"source":["#신명강 레이어 구성 옵션\n","n_hidden = 256\n","n_input = 28*28\n","n_noise = 128 #생성기의 입력값으로 사용할 노이즈의 크기"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZF-3YZ5e0zp","colab_type":"code","colab":{}},"source":["#신경망 모델 구성\n","#GAN도 Unsupervised 학습이므로 Autoencoder 처럼 Y를 사용 안함\n","X = tf.placeholder(tf.float32, [None, n_input])\n","Z = tf.placeholder(tf.float32, [None, n_noise]) #노이즈 Z를 입력값으로 사용\n","\n","#생성기 신경망에 사용하는 변수들\n","G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev = 0.01))\n","G_b1 = tf.Variable(tf.zeros([n_hidden]))\n","G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev = 0.01))\n","G_b2 = tf.Variable(tf.zeros([n_input]))\n","\n","#판별기 신경망에 사용하는 변수들\n","D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev = 0.01))\n","D_b1 = tf.Variable(tf.zeros([n_hidden]))\n","#판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라 값\n","D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev = 0.01))\n","D_b2 = tf.Variable(tf.zeros([1]))\n","\n","#생성기(G) 신경망을 구성\n","def generator(noise_z):\n","  hidden = tf.nn.relu(tf.matmul(noise_z, G_W1)+G_b1)\n","  output = tf.nn.sigmoid(tf.matmul(hidden, G_W2)+G_b2)\n","  return output\n","\n","#판별기(D) 신경망을 구성\n","def discriminator(inputs):\n","  hidden = tf.nn.relu(tf.matmul(inputs, D_W1)+ D_b1)\n","  output = tf.nn.sigmoid(tf.matmul(hidden, D_W2)+ D_b2)\n","  return output\n","\n","#랜덤한 노이즈(Z)\n","def get_noise(batch_size, n_noise):\n","  return np.random.normal(size=(batch_size, n_noise))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a40NvucZlDuE","colab_type":"code","colab":{}},"source":["#노이즈를 이용해 랜덤한 이미지를 생성합니다\n","G = generator(Z)\n","#노이즈를 이용해 생성한 이미지가 진짜 이미지인지 판별한 값을 구합니다\n","D_gene = discriminator(G)\n","\n","#진짜 이미지를 이용해 판별한 값을\n","D_real = discriminator(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9yZ5aAgYfN6v","colab_type":"code","colab":{}},"source":["loss_D = tf.reduce_mean(tf.log(D_real)+tf.log(1-D_gene))\n","\n","loss_G = tf.reduce_mean(tf.log(D_gene))\n","\n","D_var_list = [D_W1, D_b1, D_W2, D_b2]\n","G_var_list = [G_W1, G_b1, G_W2, G_b2]\n","\n","#최적화 하려는 loss_D와 loss_G에 음수 부호를 붙여줍니다.\n","train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list = D_var_list)\n","train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list = G_var_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dswUD56WfMy6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":686},"outputId":"c7b16c80-d1d7-4a94-fa5e-6babb5556c59"},"source":["sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","total_batch = int(mnist.train.num_examples/batch_size)\n","loss_val_D, loss_val_G = 0, 0\n","\n","for epoch in range(total_epoch):\n","  for i in range(total_batch):\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","    noise = get_noise(batch_size, n_noise)\n","    \n","    #판별기와 생성기 신경망을 각각 학습시킵니다\n","    _, loss_val_D = sess.run([train_D, loss_D], feed_dict = {X:batch_xs, Z:noise})\n","    _, loss_val_G = sess.run([train_G, loss_G], feed_dict = {Z:noise})\n","    \n","  print('Epoch:', '%04d'% epoch,'D loss:{:4}'.format(loss_val_D), 'G loss:{:4}'.format(loss_val_G))\n","  \n","  #학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n","  if epoch ==0 or (epoch + 1) % 10 ==0:\n","    sample_size = 10\n","    noise = get_noise(sample_size, n_noise)\n","    samples = sess.run(G, feed_dict = {Z: noise})\n","    \n","    fig, ax = plt.subplots(1, sample_size, figsize = (sample_size, 1))\n","    for i in range(sample_size):\n","      ax[i].set_axis_off()\n","      ax[i].imshow(np.reshape(samples[i],(28,28)))\n","    plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n","    plt.close(fig)\n","    print(\"최적화 완료!\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0000 D loss: 0.0 G loss:-inf\n","최적화 완료!\n","Epoch: 0001 D loss: 0.0 G loss:-inf\n","Epoch: 0002 D loss: 0.0 G loss:-inf\n","Epoch: 0003 D loss: 0.0 G loss:-inf\n","Epoch: 0004 D loss: 0.0 G loss:-inf\n","Epoch: 0005 D loss: 0.0 G loss:-inf\n","Epoch: 0006 D loss: 0.0 G loss:-inf\n","Epoch: 0007 D loss: 0.0 G loss:-inf\n","Epoch: 0008 D loss: 0.0 G loss:-inf\n","Epoch: 0009 D loss: 0.0 G loss:-inf\n","최적화 완료!\n","Epoch: 0010 D loss: 0.0 G loss:-inf\n","Epoch: 0011 D loss: 0.0 G loss:-inf\n","Epoch: 0012 D loss: 0.0 G loss:-inf\n","Epoch: 0013 D loss: 0.0 G loss:-inf\n","Epoch: 0014 D loss: 0.0 G loss:-inf\n","Epoch: 0015 D loss: 0.0 G loss:-inf\n","Epoch: 0016 D loss: 0.0 G loss:-inf\n","Epoch: 0017 D loss: 0.0 G loss:-inf\n","Epoch: 0018 D loss: 0.0 G loss:-inf\n","Epoch: 0019 D loss: 0.0 G loss:-inf\n","최적화 완료!\n","Epoch: 0020 D loss: 0.0 G loss:-inf\n","Epoch: 0021 D loss: 0.0 G loss:-inf\n","Epoch: 0022 D loss: 0.0 G loss:-inf\n","Epoch: 0023 D loss: 0.0 G loss:-inf\n","Epoch: 0024 D loss: 0.0 G loss:-inf\n","Epoch: 0025 D loss: 0.0 G loss:-inf\n","Epoch: 0026 D loss: 0.0 G loss:-inf\n","Epoch: 0027 D loss: 0.0 G loss:-inf\n","Epoch: 0028 D loss: 0.0 G loss:-inf\n","Epoch: 0029 D loss: 0.0 G loss:-inf\n","최적화 완료!\n","Epoch: 0030 D loss: 0.0 G loss:-inf\n","Epoch: 0031 D loss: 0.0 G loss:-inf\n","Epoch: 0032 D loss: 0.0 G loss:-inf\n","Epoch: 0033 D loss: 0.0 G loss:-inf\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p4aMcABrphs9","colab_type":"code","colab":{}},"source":["!mkdir -p samples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_kRx0N2pano","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}